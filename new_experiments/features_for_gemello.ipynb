{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from degree_days import  dd\n",
    "from regional_average_contribution import  contribution\n",
    "import pandas as pd\n",
    "out_overall = pickle.load(open('../data/input/all_regions.pkl','r'))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "train_region, test_region, test_home, appliance, transform, K = \"Austin\",\"SanDiego\", 203, \"hvac\",\"None\",3\n",
    "test_home = int(test_home)\n",
    "K = int(K)\n",
    "\n",
    "train_df = out_overall[train_region]\n",
    "test_df = out_overall[test_region]\n",
    "\n",
    "train_dd = pd.DataFrame(dd[train_region])\n",
    "test_dd = pd.DataFrame(dd[test_region])\n",
    "\n",
    "median_aggregate = {}\n",
    "for region in [train_region, test_region]:\n",
    "    median_aggregate[region] = {}\n",
    "    for month in range(1, 13):\n",
    "        median_aggregate[region][month] = out_overall[region]['aggregate_'+str(month)].median()\n",
    "\n",
    "median_aggregate_df = pd.DataFrame(median_aggregate)\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "start_month, end_month = 1,12\n",
    "agg_features = np.hstack([['aggregate_'+str(month) for month in range(start_month, end_month+1)],\n",
    "                         'ratio_min_max','difference_ratio_min_max','p_25','p_50','p_75','skew','kurtosis'])\n",
    "md_features = ['area','house_num_rooms']\n",
    "features = {'md_agg':np.hstack([\n",
    "            agg_features,\n",
    "            md_features\n",
    "            ]).tolist()}\n",
    "\n",
    "f_all = features['md_agg']\n",
    "\n",
    "# Find not null set of common features\n",
    "def find_com_features_train(df, home_1, home_2, featureset_max):\n",
    "    f_1 = df.ix[home_1][featureset_max].dropna()\n",
    "    f_2 = df.ix[home_2][featureset_max].dropna()\n",
    "    com_f =  np.intersect1d(f_1.index, f_2.index)\n",
    "    return com_f\n",
    "\n",
    "\n",
    "def find_distance_train_test_quick(df_train, home_1, home_2, df_test, home_test, featureset_train, featureset_max):\n",
    "    f_test = df_test.ix[home_test][featureset_max].dropna()\n",
    "    com_f =  np.intersect1d(f_test.index, featureset_train)\n",
    "    if len(com_f):\n",
    "        is_common = True\n",
    "    else:\n",
    "        is_common = False\n",
    "        return is_common, None\n",
    "\n",
    "    if len(com_f):\n",
    "        a = (df_train.ix[home_1][com_f]- df_test.ix[home_test][com_f]).abs().sum().sum()\n",
    "        b = (df_train.ix[home_2][com_f]- df_test.ix[home_test][com_f]).abs().sum().sum()\n",
    "        \n",
    "        if a<=b:\n",
    "            order = [home_1, home_2]\n",
    "        else:\n",
    "            order = [home_2, home_1]\n",
    "        return is_common, {'order':order,\n",
    "                    'num_f':len(com_f),\n",
    "                    'dist_a':a,\n",
    "                    'dist_b':b,\n",
    "                          'f':com_f}\n",
    "\n",
    "\n",
    "def find_distance_train_test(df_train, home_1, home_2, df_test, home_test, featureset_train, featureset_max):\n",
    "    f_test = df_test.ix[home_test][featureset_max].dropna()\n",
    "    com_f =  np.intersect1d(f_test.index, featureset_train)\n",
    "    if len(com_f):\n",
    "        is_common = True\n",
    "    else:\n",
    "        is_common = False\n",
    "        return is_common, None\n",
    "\n",
    "    if len(com_f):\n",
    "        a = np.linalg.norm(df_train.ix[home_1][com_f]- df_test.ix[home_test][com_f])\n",
    "        b = np.linalg.norm(df_train.ix[home_2][com_f]- df_test.ix[home_test][com_f])\n",
    "        if a<=b:\n",
    "            order = [home_1, home_2]\n",
    "        else:\n",
    "            order = [home_2, home_1]\n",
    "        return is_common, {'order':order,\n",
    "                    'num_f':len(com_f),\n",
    "                    'dist_a':a,\n",
    "                    'dist_b':b,\n",
    "                          'f':com_f}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def scale_0_1(ser, minimum=None, maximum=None):\n",
    "    if minimum is not None:\n",
    "        pass\n",
    "    else:\n",
    "        minimum = ser.min()\n",
    "        maximum = ser.max()\n",
    "    return (ser-minimum).div(maximum-minimum)\n",
    "\n",
    "def normalise(df):\n",
    "    new_df = df.copy()\n",
    "    max_aggregate = df[[\"aggregate_%d\" % i for i in range(1, 13)]].max().max()\n",
    "    min_aggregate = df[[\"aggregate_%d\" % i for i in range(1, 13)]].min().min()\n",
    "    new_df[[\"aggregate_%d\" % i for i in range(1, 13)]] = scale_0_1(df[[\"aggregate_%d\" % i for i in range(1, 13)]], min_aggregate, max_aggregate)\n",
    "    for col in ['area','num_occupants','house_num_rooms','ratio_min_max',\n",
    "                'skew','kurtosis','variance','difference_ratio_min_max','p_25',\n",
    "               'p_50','p_75']:\n",
    "        new_df[col] = scale_0_1(df[col])\n",
    "    return new_df\n",
    "\n",
    "if transform in [\"None\",\"None-percentage\"]:\n",
    "    pass\n",
    "elif transform in [\"DD\",\"DD-percentage\"]:\n",
    "    train_df_copy = train_df.copy()\n",
    "    for month in range(1, 13):\n",
    "        # index on 0, 11\n",
    "        train_dd_month = train_dd.ix[month-1]['Total']\n",
    "        test_dd_month = test_dd.ix[month-1]['Total']\n",
    "        train_df['hvac_%d' % month] = train_df_copy['hvac_%d' % month] * test_dd_month*1. / train_dd_month\n",
    "\n",
    "        #New aggregate will be removing old HVAC and adding new HVAC!\n",
    "        train_df['aggregate_%d' %month] = train_df_copy['aggregate_%d' %month] - train_df_copy['hvac_%d' % month] + train_df['hvac_%d' % month]\n",
    "elif transform in [\"median-aggregate\",\"median-aggregate-percentage\"]:\n",
    "    train_df_copy = train_df.copy()\n",
    "    for month in range(1,13):\n",
    "        median_month = median_aggregate_df.ix[month]\n",
    "        cols_to_transform = [x for x in train_df.columns if \"_\"+str(month) in x]\n",
    "        train_df[cols_to_transform] = train_df_copy[cols_to_transform] * median_month[test_region] / median_month[train_region]\n",
    "\n",
    "elif transform in [\"regional\",\"regional-percentage\"]:\n",
    "    train_df_copy = train_df.copy()\n",
    "    for month in range(1, 13):\n",
    "\n",
    "        # index on 0, 11\n",
    "        if month in range(4,11):\n",
    "            mode='Cooling'\n",
    "        else:\n",
    "            mode='Heating'\n",
    "\n",
    "        train_dd_month = contribution[train_region][mode]['hvac']\n",
    "        test_dd_month = contribution[test_region][mode]['hvac']\n",
    "\n",
    "        train_df['hvac_%d' % month] = train_df_copy['hvac_%d' % month] * test_dd_month*1. / train_dd_month\n",
    "\n",
    "        #New aggregate will be removing old HVAC and adding new HVAC!\n",
    "        train_df['aggregate_%d' %month] = train_df_copy['aggregate_%d' %month] - train_df_copy['hvac_%d' % month] + train_df['hvac_%d' % month]\n",
    "\n",
    "\n",
    "\n",
    "elif transform==\"DD-fridge\":\n",
    "    train_df_copy = train_df.copy()\n",
    "    fridge_model = pickle.load(open('../data/input/SanDiego_fridge_dd_coef.pkl','r'))\n",
    "    for month in range(1, 13):\n",
    "        # index on 0, 11\n",
    "\n",
    "        train_cdd_month = train_dd.ix[month-1]['Cooling']\n",
    "        test_cdd_month = test_dd.ix[month-1]['Cooling']\n",
    "        for fridge_home, fridge_home_model in fridge_model.iteritems():\n",
    "            train_df.loc[fridge_home,'fridge_%d' % month] = fridge_home_model['baseline']+fridge_home_model['cdd']*test_cdd_month\n",
    "            train_df.loc[fridge_home,'aggregate_%d' %month] = train_df_copy.ix[fridge_home]['aggregate_%d' %month] - train_df_copy.ix[fridge_home]['fridge_%d' % month] + train_df.ix[fridge_home]['fridge_%d' % month]\n",
    "\n",
    "overall_df = pd.concat([train_df, test_df])\n",
    "\n",
    "normalised_df = normalise(overall_df)\n",
    "\n",
    "train_normalised_df = normalised_df.ix[train_df.index]\n",
    "test_normalised_df = normalised_df.ix[test_df.index].drop_duplicates()\n",
    "\n",
    "\n",
    "def solve_ilp(inequalities, time_limit=50):\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    co = defaultdict(int)\n",
    "    for ineq in inequalities:\n",
    "        lt = ineq[0]\n",
    "        gt = ineq[1]\n",
    "        co[lt]-= 1\n",
    "        co[gt]+= 1\n",
    "    co_ser = pd.Series(co)\n",
    "    co_ser.sort()\n",
    "\n",
    "    return co_ser.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'hvac_1', u'hvac_2', u'hvac_3', u'hvac_4', u'hvac_5', u'hvac_6',\n",
       "       u'hvac_7', u'hvac_8', u'hvac_9', u'hvac_10',\n",
       "       ...\n",
       "       u'md_available', u'full_agg_available', u'ratio_min_max',\n",
       "       u'difference_ratio_min_max', u'variance', u'skew', u'kurtosis', u'p_25',\n",
       "       u'p_50', u'p_75'],\n",
       "      dtype='object', length=133)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df['md_available']&test_df['full_agg_available']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvac_1                      25\n",
       "hvac_2                      21\n",
       "hvac_3                      21\n",
       "hvac_4                      21\n",
       "hvac_5                      21\n",
       "hvac_6                      21\n",
       "hvac_7                      19\n",
       "hvac_8                      18\n",
       "hvac_9                      17\n",
       "hvac_10                     16\n",
       "hvac_11                     15\n",
       "hvac_12                     15\n",
       "wm_1                         8\n",
       "wm_2                         4\n",
       "wm_3                         4\n",
       "wm_4                         4\n",
       "wm_5                         4\n",
       "wm_6                         4\n",
       "wm_7                         3\n",
       "wm_8                         3\n",
       "wm_9                         2\n",
       "wm_10                        2\n",
       "wm_11                        2\n",
       "wm_12                        2\n",
       "fridge_1                    23\n",
       "fridge_2                    20\n",
       "fridge_3                    20\n",
       "fridge_4                    20\n",
       "fridge_5                    20\n",
       "fridge_6                    20\n",
       "                            ..\n",
       "dw_8                        18\n",
       "dw_9                        17\n",
       "dw_10                       16\n",
       "dw_11                       15\n",
       "dw_12                       15\n",
       "dr_1                         0\n",
       "dr_2                         0\n",
       "dr_3                         0\n",
       "dr_4                         0\n",
       "dr_5                         0\n",
       "dr_6                         0\n",
       "dr_7                         0\n",
       "dr_8                         0\n",
       "dr_9                         0\n",
       "dr_10                        0\n",
       "dr_11                        0\n",
       "dr_12                        0\n",
       "house_num_rooms              8\n",
       "area                         8\n",
       "num_occupants                8\n",
       "md_available                42\n",
       "full_agg_available          42\n",
       "ratio_min_max               15\n",
       "difference_ratio_min_max    15\n",
       "variance                    15\n",
       "skew                        15\n",
       "kurtosis                    15\n",
       "p_25                        15\n",
       "p_50                        15\n",
       "p_75                        15\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe().ix['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_compute=1\n",
    "candidate_homes = train_normalised_df['%s_%d' %(appliance, month_compute)].dropna().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  22,   26,   59,   77,   86,   93,   94,  101,  114,  115,  121,\n",
       "        130,  135,  160,  187,  222,  267,  297,  347,  364,  370,  410,\n",
       "        434,  436,  457,  484,  491,  499,  503,  508,  545,  580,  624,\n",
       "        645,  661,  668,  739,  744,  772,  781,  796,  871,  878,  898,\n",
       "        936,  946,  954,  974,  980,  994, 1037, 1069, 1086, 1105, 1169,\n",
       "       1185, 1192, 1202, 1283, 1310, 1314, 1331, 1334, 1403, 1415, 1463,\n",
       "       1479, 1500, 1507, 1551, 1586, 1589, 1617, 1632, 1642, 1681, 1697,\n",
       "       1700, 1714, 1718, 1790, 1791, 1796, 1800, 1854, 1889, 1947, 1953,\n",
       "       1994, 2004, 2018, 2034, 2094, 2129, 2156, 2158, 2171, 2199, 2233,\n",
       "       2242, 2335, 2361, 2365, 2366, 2378, 2401, 2458, 2461, 2470, 2472,\n",
       "       2510, 2520, 2532, 2557, 2575, 2638, 2641, 2751, 2755, 2769, 2787,\n",
       "       2814, 2818, 2829, 2845, 2859, 2864, 2907, 2945, 2953, 2965, 2974,\n",
       "       2992, 3009, 3036, 3039, 3044, 3134, 3192, 3268, 3273, 3299, 3310,\n",
       "       3367, 3411, 3413, 3425, 3443, 3456, 3482, 3484, 3500, 3506, 3510,\n",
       "       3527, 3531, 3538, 3577, 3631, 3635, 3649, 3652, 3678, 3719, 3721,\n",
       "       3723, 3736, 3778, 3829, 3831, 3849, 3873, 3893, 3916, 3918, 3935,\n",
       "       3967, 4022, 4042, 4053, 4135, 4154, 4193, 4213, 4220, 4296, 4297,\n",
       "       4298, 4302, 4336, 4342, 4352, 4357, 4373, 4375, 4416, 4447, 4473,\n",
       "       4505, 4514, 4526, 4575, 4641, 4660, 4732, 4767, 4776, 4800, 4856,\n",
       "       4864, 4874, 4922, 4946, 4957, 4998, 5026, 5060, 5109, 5129, 5209,\n",
       "       5218, 5275, 5317, 5356, 5357, 5371, 5395, 5403, 5539, 5545, 5552,\n",
       "       5568, 5673, 5677, 5718, 5746, 5778, 5785, 5786, 5809, 5810, 5814,\n",
       "       5874, 5889, 5921, 5949, 5959, 5972, 6061, 6063, 6072, 6078, 6101,\n",
       "       6108, 6139, 6165, 6286, 6324, 6334, 6348, 6412, 6418, 6423, 6460,\n",
       "       6498, 6500, 6614, 6636, 6673, 6688, 6691, 6692, 6730, 6799, 6836,\n",
       "       6871, 6910, 6911, 6941, 6990, 7016, 7017, 7024, 7030, 7036, 7057,\n",
       "       7117, 7122, 7276, 7287, 7319, 7390, 7429, 7436, 7491, 7504, 7510,\n",
       "       7512, 7527, 7531, 7536, 7549, 7560, 7627, 7638, 7641, 7680, 7703,\n",
       "       7719, 7731, 7764, 7769, 7787, 7788, 7793, 7794, 7800, 7850, 7863,\n",
       "       7866, 7875, 7900, 7901, 7940, 7951, 7965, 7973, 7984, 7989, 8034,\n",
       "       8046, 8079, 8084, 8086, 8092, 8122, 8142, 8156, 8163, 8183, 8188,\n",
       "       8197, 8236, 8243, 8282, 8292, 8317, 8386, 8419, 8467, 8565, 8589,\n",
       "       8600, 8645, 8669, 8741, 8767, 8807, 8829, 8890, 8956, 8967, 8995,\n",
       "       9001, 9019, 9052, 9121, 9134, 9141, 9160, 9182, 9195, 9201, 9215,\n",
       "       9248, 9251, 9278, 9295, 9340, 9343, 9356, 9484, 9498, 9578, 9609,\n",
       "       9613, 9624, 9647, 9654, 9674, 9701, 9729, 9737, 9745, 9766, 9771,\n",
       "       9773, 9803, 9875, 9912, 9915, 9919, 9922, 9926, 9929, 9931, 9932,\n",
       "       9933, 9934, 9935, 9937, 9938, 9939, 9942, 9971, 9981, 9982])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_homes = np.array(np.setdiff1d(candidate_homes, test_home))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,b= next(combinations(candidate_homes, 2))\n",
    "a,b\n",
    "com_features = find_com_features_train(train_df, a, b, f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aggregate_1', 'aggregate_2', 'aggregate_3', 'aggregate_4',\n",
       "       'aggregate_5', 'aggregate_6'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 21.34 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "100 loops, best of 3: 3.09 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit is_common, d = find_distance_train_test(train_normalised_df, a, b, test_normalised_df, test_home, com_features, f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.86 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit is_common, d = find_distance_train_test_quick(train_normalised_df, a, b, test_normalised_df, test_home, com_features, f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for month_compute in range(1, 13):\n",
    "\n",
    "    from collections import Counter, defaultdict\n",
    "    num_features_all = {}\n",
    "    ineq_dict = {}\n",
    "\n",
    "    num_features_all[appliance] = {}\n",
    "    ineq_dict[appliance] = {}\n",
    "\n",
    "    #num_features_all[appliance][month_compute] = {}\n",
    "    ineq_dict[appliance][month_compute] = {}\n",
    "\n",
    "    candidate_homes = train_normalised_df['%s_%d' %(appliance, month_compute)].dropna().index.values\n",
    "\n",
    "\n",
    "\n",
    "    #num_features_all[appliance][month_compute][test_home] = defaultdict(int)\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    co = defaultdict(int)\n",
    "    store_path = '../../../output/output/ineq_cross/%s_%s_%s_%s_%d_%d_%d.pkl' %(train_region,\n",
    "                                                                        test_region,\n",
    "                                                                        transform,\n",
    "                                                                        appliance,\n",
    "                                                                        month_compute,\n",
    "                                                                        test_home, K)\n",
    "    print store_path\n",
    "    if os.path.exists(store_path):\n",
    "        print \"already exists\"\n",
    "        continue\n",
    "\n",
    "\n",
    "    if not np.isnan(test_normalised_df.ix[test_home]['%s_%d' %(appliance, month_compute)]):\n",
    "        # We need to predict this value!\n",
    "        # Find candidate set, train homes which have not null for this month\n",
    "        # Now find features on pairs of homes in candidate homes\n",
    "        for a,b in combinations(candidate_homes, 2):\n",
    "            com_features = find_com_features_train(train_df, a, b, f_all)\n",
    "\n",
    "            if len(com_features):\n",
    "                # Consider a,b\n",
    "                is_common, d = find_distance_train_test(train_normalised_df, a, b, test_normalised_df, test_home, com_features, f_all)\n",
    "                if is_common:\n",
    "\n",
    "                    # Common between train and test. Can add this pair to inequalities\n",
    "                    ineq=d['order']\n",
    "                    lt = ineq[0]\n",
    "                    gt = ineq[1]\n",
    "                    co[lt]-= 1\n",
    "                    co[gt]+= 1\n",
    "                    #num_features_all[appliance][month_compute][test_home][d['num_f']]+= 1\n",
    "\n",
    "        \"\"\"\n",
    "        # Saving ineqs\n",
    "        pickle.dump(ineqs, open('../data/model/inequalities/%s_%s_%s_%s_%d_%d.pkl' %(train_region,\n",
    "                                                                        test_region,\n",
    "                                                                        transform,\n",
    "                                                                        appliance,\n",
    "                                                                        month_compute,\n",
    "                                                                        test_home),'w'))\n",
    "        \"\"\"\n",
    "        co_ser = pd.Series(co)\n",
    "        co_ser.sort()\n",
    "        ranks = co_ser.index.values.tolist()\n",
    "        if \"percentage\" in transform:\n",
    "            mean_proportion = (train_df.ix[ranks[:K]]['%s_%d' %(appliance, month_compute)]/ train_df.ix[ranks[:K]]['aggregate_%d' %(month_compute)]).mean()\n",
    "\n",
    "            pred = test_df.ix[test_home]['aggregate_%d' %month_compute]*mean_proportion\n",
    "\n",
    "        else:\n",
    "            pred = train_df.ix[ranks[:K]]['%s_%d' %(appliance, month_compute)].dropna().mean()\n",
    "        gt = test_df.ix[test_home]['%s_%d' %(appliance, month_compute)]\n",
    "        pickle.dump(pred, open(store_path,'w'))\n",
    "\n",
    "\n",
    "    else:\n",
    "        # No need to predict\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
